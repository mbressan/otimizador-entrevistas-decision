# ğŸš€ Otimizador de Entrevistas com InteligÃªncia Artificial

Sistema completo de otimizaÃ§Ã£o de entrevistas que utiliza Machine Learning para identificar os candidatos mais compatÃ­veis com vagas especÃ­ficas, desenvolvido com Flask, PostgreSQL, Docker e monitorizaÃ§Ã£o avanÃ§ada.

## ğŸ“‹ Ãndice

- [CaracterÃ­sticas](#caracterÃ­sticas)
- [Arquitetura](#arquitetura)
- [PrÃ©-requisitos](#prÃ©-requisitos)
- [InstalaÃ§Ã£o e ExecuÃ§Ã£o](#instalaÃ§Ã£o-e-execuÃ§Ã£o)
- [Uso da AplicaÃ§Ã£o](#uso-da-aplicaÃ§Ã£o)
- [API REST](#api-rest)
- [MonitorizaÃ§Ã£o](#monitorizaÃ§Ã£o)
- [Testes](#testes)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [Tecnologias Utilizadas](#tecnologias-utilizadas)

## âœ¨ CaracterÃ­sticas

- **ğŸ§  Machine Learning Aprimorado**: Modelo Random Forest com 7 features avanÃ§adas incluindo TF-IDF, compatibilidade tÃ©cnica, acadÃªmica e linguÃ­stica
- **ğŸ—„ï¸ Banco PostgreSQL**: Banco de dados robusto com Ã­ndices GIN para busca full-text em portuguÃªs
- **ğŸŒ Interface Web**: Dashboard intuitivo para visualizaÃ§Ã£o de vagas e candidatos
- **ğŸ“Š Score de Compatibilidade**: Probabilidade de contrataÃ§Ã£o baseada em dados histÃ³ricos
- **ğŸ” Busca AvanÃ§ada**: Sistema de busca full-text otimizado com PostgreSQL
- **ğŸ“ˆ MonitorizaÃ§Ã£o**: Prometheus e Grafana para mÃ©tricas em tempo real
- **ğŸ³ ContainerizaÃ§Ã£o**: Deploy completo com Docker e Docker Compose
- **ğŸ›¡ï¸ SeguranÃ§a**: ImplementaÃ§Ã£o de boas prÃ¡ticas de seguranÃ§a
- **ğŸ§ª Testes**: Suite completa de testes unitÃ¡rios e de integraÃ§Ã£o

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Nginx       â”‚â”€â”€â”€â”€â”‚   Flask App     â”‚â”€â”€â”€â”€â”‚   Prometheus    â”‚
â”‚ (Load Balancer) â”‚    â”‚ (API + Web UI)  â”‚    â”‚   (Metrics)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                       â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   PostgreSQL    â”‚    â”‚     Grafana     â”‚
                       â”‚   Database      â”‚    â”‚  (Dashboard)    â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚ Machine Learningâ”‚
                       â”‚    Pipeline     â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ PrÃ©-requisitos

- **Docker** 20.10+
- **Docker Compose** 2.0+
- **Git**

## ğŸš€ InstalaÃ§Ã£o e ExecuÃ§Ã£o

### 1. Clone o RepositÃ³rio

```bash
git clone <repository-url>
cd otimizador-entrevistas
```

### 2. Executar com Docker

#### Stack Completa (Recomendado)
```bash
# Executar toda a stack (PostgreSQL + App + Prometheus + Grafana)
docker-compose up --build

# Executar em background
docker-compose up -d --build
```

#### Verificar Status dos ServiÃ§os
```bash
# Verificar containers rodando
docker-compose ps

# Verificar logs da aplicaÃ§Ã£o
docker-compose logs app

# Verificar logs do PostgreSQL
docker-compose logs postgresql
```

#### Comandos Ãšteis
```bash
# Parar todos os serviÃ§os
docker-compose down

# Parar e remover volumes (dados)
docker-compose down -v

# Reconstruir apenas a aplicaÃ§Ã£o
docker-compose up --build app

# Executar comandos dentro do container
docker-compose exec app bash
docker-compose exec postgresql psql -U postgres -d otimizador_entrevistas
```

**âš ï¸ IMPORTANTE**: Na primeira execuÃ§Ã£o, o sistema:
1. **VerificarÃ¡ automaticamente** se o PostgreSQL estÃ¡ disponÃ­vel
2. **CriarÃ¡ o esquema do banco** se nÃ£o existir
3. **PopularÃ¡ automaticamente** com os dados dos arquivos JSON
4. **MigrarÃ¡** vagas, candidatos e prospects para PostgreSQL

Este processo pode levar alguns minutos na primeira execuÃ§Ã£o. As execuÃ§Ãµes subsequentes serÃ£o mais rÃ¡pidas pois os dados jÃ¡ estarÃ£o no banco.

## ğŸŒ Acesso aos ServiÃ§os

ApÃ³s a execuÃ§Ã£o com `docker-compose up`:

- **ğŸ–¥ï¸ AplicaÃ§Ã£o Principal**: http://localhost
- **ğŸ—„ï¸ PostgreSQL**: localhost:5432 (acesso interno)
- **ğŸ“Š Prometheus**: http://localhost:9090
- **ğŸ“ˆ Grafana**: http://localhost:3000
  - UsuÃ¡rio: `admin`
  - Senha: `admin123`

## ğŸ—„ï¸ InicializaÃ§Ã£o AutomÃ¡tica do Banco de Dados

### Processo AutomÃ¡tico
A aplicaÃ§Ã£o possui **inicializaÃ§Ã£o automÃ¡tica do PostgreSQL** que Ã© executada durante o startup:

1. **ğŸ” VerificaÃ§Ã£o**: Detecta se PostgreSQL estÃ¡ disponÃ­vel
2. **ğŸ—ï¸ CriaÃ§Ã£o do Esquema**: Cria tabelas se nÃ£o existirem
3. **ğŸ“Š VerificaÃ§Ã£o de Dados**: Checa se jÃ¡ existem dados no banco
4. **ğŸš€ MigraÃ§Ã£o AutomÃ¡tica**: Migra dados JSON â†’ PostgreSQL se necessÃ¡rio
5. **âœ… ValidaÃ§Ã£o**: Confirma que a migraÃ§Ã£o foi bem-sucedida

### Tabelas Criadas Automaticamente
- **`vagas`**: InformaÃ§Ãµes das vagas com Ã­ndices otimizados
- **`candidatos`**: Perfis dos candidatos
- **`prospects`**: HistÃ³rico de candidaturas (variÃ¡vel alvo para ML)
- **`predicoes`**: Resultados das prediÃ§Ãµes do modelo

### Logs de InicializaÃ§Ã£o
Durante o startup, vocÃª verÃ¡ logs como:
```
ğŸ” Verificando estado do banco de dados PostgreSQL...
âœ… PostgreSQL estÃ¡ disponÃ­vel!
ğŸ“ Banco vazio detectado. Iniciando populaÃ§Ã£o automÃ¡tica...
ğŸš€ Configurando banco de dados PostgreSQL...
ğŸ“‹ Criando tabelas PostgreSQL...
ğŸš€ Migrando dados para PostgreSQL...
âœ… PostgreSQL configurado e populado com sucesso!
ğŸ‰ Banco de dados inicializado com sucesso!
```

### Fallback Inteligente
Se PostgreSQL nÃ£o estiver disponÃ­vel, a aplicaÃ§Ã£o automaticamente:
- âš ï¸ Detecta a indisponibilidade do banco
- ğŸ”„ Ativa modo fallback JSON
- ğŸ“ Carrega dados diretamente dos arquivos JSON
- ğŸš€ Continua funcionando normalmente

## ğŸ’» Uso da AplicaÃ§Ã£o

### Dashboard Principal
1. Acesse http://localhost
2. Visualize todas as vagas disponÃ­veis
3. Use filtros de busca por tÃ­tulo, cliente ou nÃ­vel

### AnÃ¡lise de Compatibilidade
1. Clique em "Ver Candidatos CompatÃ­veis" em qualquer vaga
2. Visualize candidatos ordenados por score de compatibilidade (baseado em dados do PostgreSQL)
3. Analise informaÃ§Ãµes detalhadas de cada candidato
4. Use busca full-text avanÃ§ada para encontrar competÃªncias especÃ­ficas

### InterpretaÃ§Ã£o dos Scores
- **ğŸŸ¢ 80-100%**: Excelente compatibilidade
- **ğŸ”µ 60-79%**: Boa compatibilidade  
- **ğŸŸ¡ 40-59%**: Compatibilidade regular
- **ğŸ”´ 0-39%**: Baixa compatibilidade

## ğŸ”Œ API REST

### Endpoint de PrediÃ§Ã£o

```bash
POST /api/predict
Content-Type: application/json

{
  "competencias_combinadas": "python flask django postgresql",
  "nivel_profissional": "senior",
  "areas_atuacao": "desenvolvimento"
}
```

**Resposta:**
```json
{
  "prediction": 1,
  "probability": {
    "not_hired": 0.3,
    "hired": 0.7
  },
  "match_score": 70.0
}
```

### Health Check

```bash
GET /health
```

## ğŸ“Š MonitorizaÃ§Ã£o

### Prometheus
- **URL**: http://localhost:9090
- **MÃ©tricas Coletadas**:
  - RequisiÃ§Ãµes HTTP por endpoint
  - Tempo de resposta
  - Uso de CPU e memÃ³ria
  - Erros da aplicaÃ§Ã£o

### Grafana
- **URL**: http://localhost:3000
- **Login**: admin/admin123
- **Dashboards IncluÃ­dos**:
  - **Dashboard Principal**: MÃ©tricas da aplicaÃ§Ã£o, ML e performance
  - **Dashboard de Infraestrutura**: Status dos containers e recursos do sistema

### Dashboards AutomÃ¡ticos

Os dashboards sÃ£o automaticamente configurados ao iniciar o Grafana:

1. **Dashboard Principal** (`main-dashboard.json`):
   - Taxa de requisiÃ§Ãµes por segundo
   - Tempo de resposta (95th percentile) 
   - Total de requisiÃ§Ãµes por endpoint
   - Taxa de sucesso das requisiÃ§Ãµes
   - PrediÃ§Ãµes de ML por hora
   - Tempo de resposta das prediÃ§Ãµes

2. **Dashboard de Infraestrutura** (`infrastructure-dashboard.json`):
   - Status dos containers (Flask, PostgreSQL, Prometheus, Nginx)
   - ConexÃµes PostgreSQL ativas
   - TransaÃ§Ãµes de banco de dados
   - Uso de memÃ³ria e CPU por container

### Acesso RÃ¡pido
- **AplicaÃ§Ã£o**: http://localhost
- **Grafana**: http://localhost:3000 (admin/admin123)
- **Prometheus**: http://localhost:9090

## ğŸ§ª Testes

### Executar Testes no Docker

```bash
# Executar testes dentro do container
docker-compose exec app python -m pytest tests/ -v

# Executar testes com cobertura
docker-compose exec app python -m pytest tests/ --cov=app --cov-report=html
```

## ğŸ”¬ Treinamento do Modelo

### Executar Treinamento via Docker

```bash
# Acessar o container da aplicaÃ§Ã£o
docker-compose exec app bash

# Executar o notebook de treinamento
cd notebooks
jupyter nbconvert --to notebook --execute Treinamento.ipynb --output Treinamento_executed.ipynb
```

### Workflow dos Notebooks

O projeto utiliza dois notebooks para o treinamento:

1. **`Treinamento.ipynb`** - Notebook principal para desenvolvimento
   - ContÃ©m o pipeline completo de Machine Learning
   - ConfiguraÃ§Ã£o e migraÃ§Ã£o automÃ¡tica para PostgreSQL
   - Versionado no Git

2. **`Treinamento_executed.ipynb`** - Notebook executado automaticamente
   - Gerado pela execuÃ§Ã£o do notebook principal
   - ContÃ©m todas as saÃ­das das cÃ©lulas executadas
   - NÃ£o versionado no Git (adicionado ao .gitignore)

### Resultados do Treinamento

ApÃ³s o treinamento, o modelo serÃ¡ salvo em:
- `app/models/pipeline_aprimorado.joblib` - Modelo treinado
- `app/models/model_metadata_enhanced.json` - Metadados do modelo

## ğŸ“ Estrutura do Projeto

```
otimizador-entrevistas/
â”œâ”€â”€ app/                          # AplicaÃ§Ã£o Flask
â”‚   â”œâ”€â”€ models/                   # Modelos treinados
â”‚   â”‚   â”œâ”€â”€ pipeline_aprimorado.joblib
â”‚   â”‚   â””â”€â”€ model_metadata_enhanced.json
â”‚   â”œâ”€â”€ templates/                # Templates HTML
â”‚   â”‚   â”œâ”€â”€ index.html
â”‚   â”‚   â””â”€â”€ vaga_detalhes.html
â”‚   â”œâ”€â”€ app.py                    # AplicaÃ§Ã£o principal
â”‚   â”œâ”€â”€ postgresql_integration.py # IntegraÃ§Ã£o PostgreSQL
â”‚   â”œâ”€â”€ requirements.txt          # DependÃªncias Python
â”‚   â”œâ”€â”€ .env.example             # ConfiguraÃ§Ãµes PostgreSQL
â”‚   â””â”€â”€ Dockerfile               # Container da aplicaÃ§Ã£o
â”œâ”€â”€ data/                        # Dados fonte (JSON)
â”‚   â”œâ”€â”€ vagas.json              # Dados das vagas
â”‚   â”œâ”€â”€ applicants.json         # Dados dos candidatos
â”‚   â””â”€â”€ prospects.json          # Dados dos prospects
â”œâ”€â”€ notebooks/                  # Jupyter Notebooks
â”‚   â”œâ”€â”€ Treinamento.ipynb      # Pipeline de ML com PostgreSQL
â”‚   â””â”€â”€ Treinamento_executed.ipynb  # Notebook executado (auto-gerado)
â”œâ”€â”€ tests/                     # Testes automatizados
â”‚   â””â”€â”€ test_api.py           # Testes da API
â”œâ”€â”€ docker-compose.yml        # OrquestraÃ§Ã£o completa
â”œâ”€â”€ prometheus.yml           # ConfiguraÃ§Ã£o Prometheus
â”œâ”€â”€ nginx.conf              # ConfiguraÃ§Ã£o Nginx
â””â”€â”€ README.md              # DocumentaÃ§Ã£o
```

## ğŸ› ï¸ Tecnologias Utilizadas

### Backend
- **Flask** 3.0.0 - Framework web
- **Gunicorn** 21.2.0 - Servidor WSGI
- **PostgreSQL** 15+ - Banco de dados principal
- **psycopg2-binary** 2.9.0 - Driver PostgreSQL
- **SQLAlchemy** 2.0.0 - ORM e abstraÃ§Ã£o de banco
- **Pandas** 2.1.4 - ManipulaÃ§Ã£o de dados
- **Scikit-learn** 1.3.2 - Machine Learning
- **Joblib** 1.3.2 - SerializaÃ§Ã£o de modelos

### Machine Learning
- **Random Forest Classifier** - Modelo de classificaÃ§Ã£o
- **TF-IDF Vectorizer** - Processamento de texto
- **One Hot Encoder** - CodificaÃ§Ã£o categÃ³rica
- **Column Transformer** - Pipeline de prÃ©-processamento
- **PostgreSQL Full-Text Search** - Busca semÃ¢ntica integrada

### Frontend
- **Bootstrap** 5.1.3 - Framework CSS
- **Font Awesome** 6.0.0 - Ãcones
- **JavaScript** - Interatividade

### DevOps e MonitorizaÃ§Ã£o
- **Docker** & **Docker Compose** - ContainerizaÃ§Ã£o
- **Nginx** - Load Balancer e Proxy Reverso
- **Prometheus** - Coleta de mÃ©tricas
- **Grafana** - VisualizaÃ§Ã£o de mÃ©tricas
- **Prometheus Flask Exporter** - MÃ©tricas da aplicaÃ§Ã£o

### Testes
- **Pytest** 7.4.3 - Framework de testes
- **Coverage** - Cobertura de cÃ³digo

## ğŸ”§ ConfiguraÃ§Ã£o AvanÃ§ada

### VariÃ¡veis de Ambiente

```bash
# PostgreSQL
DB_HOST=localhost
DB_NAME=otimizador_entrevistas
DB_USER=postgres
DB_PASSWORD=postgres
DB_PORT=5432

# AplicaÃ§Ã£o
FLASK_ENV=production
DEBUG=false
PORT=5000

# Grafana
GF_SECURITY_ADMIN_PASSWORD=admin123
GF_USERS_ALLOW_SIGN_UP=false
```

### ConfiguraÃ§Ã£o de ProduÃ§Ã£o

Para ambiente de produÃ§Ã£o com Docker:

1. **Configurar variÃ¡veis de ambiente personalizadas**:
   ```bash
   # Criar arquivo .env
   cp app/.env.example .env
   # Editar .env com configuraÃ§Ãµes de produÃ§Ã£o
   ```

2. **Executar com configuraÃ§Ãµes otimizadas**:
   ```bash
   docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d
   ```

3. **ConfiguraÃ§Ãµes recomendadas**:
   - Alterar senhas padrÃ£o do PostgreSQL
   - Configurar HTTPS com certificados
   - Configurar backup automatizado do PostgreSQL
   - Implementar log centralizado
   - Configurar replicaÃ§Ã£o PostgreSQL para alta disponibilidade

## ğŸ¤ ContribuiÃ§Ã£o

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

## ğŸ“ Suporte

Para suporte e dÃºvidas:
- Abra uma issue no GitHub
- Consulte a documentaÃ§Ã£o tÃ©cnica
- Verifique os logs da aplicaÃ§Ã£o

---

**ğŸ‰ Desenvolvido com â¤ï¸ usando Flask, Machine Learning e DevOps Best Practices**
