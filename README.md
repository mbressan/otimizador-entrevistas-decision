# ğŸš€ Otimizador de Entrevistas com Machine Learning

## ğŸ“ InformaÃ§Ãµes AcadÃªmicas

**Projeto**: PÃ“S TECH - Datathon - Machine Learning Engineering  
**InstituiÃ§Ã£o**: FIAP - Faculdade de InformÃ¡tica e AdministraÃ§Ã£o Paulista  
**Fase**: 5  
**Autor**: Mateus Bressan  
**Ano**: 2025  

## ğŸ“– Sobre o Projeto

Sistema de otimizaÃ§Ã£o de entrevistas que utiliza Machine Learning para identificar os candidatos mais compatÃ­veis com vagas especÃ­ficas. O projeto foi desenvolvido como entregÃ¡vel do Datathon de Machine Learning Engineering, implementando uma soluÃ§Ã£o completa de MLOps com Flask, Docker e monitoramento em tempo real.

### ğŸ¯ Objetivo do Datathon

Desenvolver uma soluÃ§Ã£o de Machine Learning end-to-end que demonstre:
- **Engenharia de Features** para otimizaÃ§Ã£o de compatibilidade candidato-vaga
- **Pipeline de ML** robusto e escalÃ¡vel com Random Forest
- **MLOps** completo com containerizaÃ§Ã£o Docker
- **Monitoramento** de modelos em produÃ§Ã£o com Prometheus/Grafana
- **API REST** para integraÃ§Ã£o e consumo de prediÃ§Ãµes
- **Interface Web** responsiva para anÃ¡lise em tempo real

## ğŸ¬ DemonstraÃ§Ã£o

**VÃ­deo de ApresentaÃ§Ã£o**: [URL_DO_VIDEO_AQUI]

## ğŸ“‹ Ãndice

- [InformaÃ§Ãµes AcadÃªmicas](#informaÃ§Ãµes-acadÃªmicas)
- [Sobre o Projeto](#sobre-o-projeto)
- [CaracterÃ­sticas](#caracterÃ­sticas)
- [Arquitetura](#arquitetura)
- [InstalaÃ§Ã£o e ExecuÃ§Ã£o via Docker](#instalaÃ§Ã£o-e-execuÃ§Ã£o-via-docker)
- [Uso da AplicaÃ§Ã£o](#uso-da-aplicaÃ§Ã£o)
- [API REST](#api-rest)
- [MonitorizaÃ§Ã£o](#monitorizaÃ§Ã£o)
- [Testes](#testes)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [Tecnologias Utilizadas](#tecnologias-utilizadas)

## âœ¨ CaracterÃ­sticas

- **ğŸ§  Machine Learning Especializado**: Modelo Random Forest com 99.1% de acurÃ¡cia treinado especificamente para prediÃ§Ã£o de compatibilidade candidato-vaga baseado em padrÃµes de contrataÃ§Ãµes bem-sucedidas.
- **ğŸŒ Interface Web Responsiva**: Dashboard intuitivo desenvolvido com Bootstrap 5 para anÃ¡lise de compatibilidade em tempo real.
- **ğŸ”Œ API REST Completa**: Endpoints otimizados para integraÃ§Ã£o externa e consumo interno da aplicaÃ§Ã£o web.
- **ğŸ“Š AnÃ¡lise Detalhada**: Score de compatibilidade com breakdown por categoria (tÃ©cnica, acadÃªmica, idiomas) e justificativas detalhadas.
- **ğŸ“‚ Arquitetura Simplificada**: Sistema baseado em arquivos JSON para mÃ¡xima portabilidade e facilidade de deploy.
- **ğŸ“ˆ MonitorizaÃ§Ã£o AvanÃ§ada**: Stack completa Prometheus + Grafana com mÃ©tricas de ML e infraestrutura.
- **ğŸ³ ContainerizaÃ§Ã£o Completa**: Deploy via Docker Compose com todos os serviÃ§os orquestrados.
- **ğŸ§ª Testes Automatizados**: SuÃ­te completa de testes via pytest e Postman com validaÃ§Ãµes automÃ¡ticas.
- **ğŸš€ MLOps**: Pipeline completo de Machine Learning com monitoramento de drift e retreinamento.

## ğŸ—ï¸ Arquitetura

A soluÃ§Ã£o implementa uma arquitetura de MLOps completa, otimizada para performance e facilidade de manutenÃ§Ã£o, utilizando uma abordagem baseada em arquivos JSON para mÃ¡xima portabilidade.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Nginx       â”‚â”€â”€â”€â”€â”‚   Flask App     â”‚â”€â”€â”€â”€â”‚   Prometheus    â”‚
â”‚ (Load Balancer) â”‚    â”‚ (API + Web UI)  â”‚    â”‚   (Metrics)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                      â”‚                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  JSON Data Storage   â”‚   â”‚ ML Pipeline     â”‚    â”‚     Grafana     â”‚
â”‚ â€¢ applicants.json    â”‚   â”‚ Random Forest   â”‚    â”‚  (Dashboards)   â”‚
â”‚ â€¢ vagas.json         â”‚   â”‚ 99.1% Accuracy  â”‚    â”‚ â€¢ ML Metrics    â”‚
â”‚ â€¢ prospects.json     â”‚   â”‚ â€¢ Feature Eng.  â”‚    â”‚ â€¢ Infrastructureâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â€¢ Preprocessing â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚ â€¢ Validation    â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ¯ Componentes Principais

#### **Machine Learning Engine**
- **Pipeline Completo**: Preprocessamento + Feature Engineering + Modelo
- **Modelo**: Random Forest especializado em padrÃµes de contrataÃ§Ã£o
- **Features**: 21 caracterÃ­sticas otimizadas (tÃ©cnicas, acadÃªmicas, idiomas)
- **ValidaÃ§Ã£o**: Cross-validation e mÃ©tricas de performance contÃ­nuas

#### **API REST**
- **`/`** - Interface web para anÃ¡lise de compatibilidade
- **`/api/predict`** - Endpoint principal para prediÃ§Ãµes ML
- **`/health`** - Health check para monitoramento
- **`/status`** - Status detalhado de todos os componentes

#### **Monitoramento MLOps**
- **MÃ©tricas de ML**: AcurÃ¡cia, distribuiÃ§Ã£o de scores, drift detection
- **MÃ©tricas de Sistema**: CPU, memÃ³ria, latÃªncia, throughput
- **Alertas**: DegradaÃ§Ã£o de performance, falhas de modelo

## ï¿½ InstalaÃ§Ã£o e ExecuÃ§Ã£o via Docker

### PrÃ©-requisitos

- **Docker** 20.10+
- **Docker Compose** 2.0+
- **Git**

### 1. Clone o RepositÃ³rio

```bash
git clone https://github.com/mbressan/otimizador-entrevistas-decision.git
cd otimizador-entrevistas-decision
```

### 2. ExecuÃ§Ã£o Completa (Recomendado)

O projeto foi projetado para execuÃ§Ã£o principal via Docker, incluindo toda a stack de monitoramento:

```bash
# Executar toda a stack
docker-compose up --build

# Executar em background
docker-compose up -d --build
```

**ServiÃ§os DisponÃ­veis**:
- **AplicaÃ§Ã£o Principal**: http://localhost *(via Nginx)*
- **API Direta**: http://localhost:5000 *(Flask app)*
- **Prometheus**: http://localhost:9090
- **Grafana**: http://localhost:3000 *(admin/admin123)*

### 3. ExecuÃ§Ã£o Simples (Desenvolvimento)

Para desenvolvimento local sem monitoramento:

```bash
# Instalar dependÃªncias
pip install -r app/requirements.txt

# Executar aplicaÃ§Ã£o Flask
python app/app.py
```

**Acesso**: http://localhost:5000

### 4. ValidaÃ§Ã£o do Deploy

```bash
# Verificar status dos containers
docker-compose ps

# Testar health check
curl http://localhost/health

# Testar prediÃ§Ã£o via API
curl -X POST http://localhost/api/predict \
  -H "Content-Type: application/json" \
  -d '{"vaga": {"titulo_vaga": "Desenvolvedor Python"}, "candidato": {"conhecimentos_tecnicos": "Python"}}'
```

## ğŸ’» Uso da AplicaÃ§Ã£o

### Interface Web

1. **Acesse a aplicaÃ§Ã£o**: http://localhost *(Docker)* ou http://localhost:5000 *(local)*
2. **Preencha os dados da vaga** no formulÃ¡rio da esquerda:
   - TÃ­tulo da vaga
   - CompetÃªncias tÃ©cnicas requeridas
   - NÃ­vel acadÃªmico, profissional e inglÃªs
   - Tipo de contrataÃ§Ã£o e Ã¡rea de atuaÃ§Ã£o
3. **Preencha os dados do candidato** no formulÃ¡rio da direita:
   - Conhecimentos tÃ©cnicos
   - NÃ­vel acadÃªmico, inglÃªs e Ã¡rea de atuaÃ§Ã£o
4. **Clique em "Analisar Compatibilidade"**
5. **Visualize o resultado**:
   - Score de compatibilidade (0-100%)
   - ClassificaÃ§Ã£o (Alta/Baixa Qualidade)
   - AnÃ¡lise detalhada por categoria
   - Justificativas e recomendaÃ§Ãµes

### InterpretaÃ§Ã£o dos Resultados

#### Scores de Compatibilidade
- **80-100%**: **Alta Qualidade** - Candidato altamente compatÃ­vel
- **60-79%**: **Qualidade Moderada** - Boa compatibilidade com gaps menores
- **40-59%**: **Qualidade MÃ©dia** - Compatibilidade parcial
- **0-39%**: **Baixa Qualidade** - Pouca compatibilidade

#### AnÃ¡lise Detalhada
- **Compatibilidade TÃ©cnica**: Match entre competÃªncias requeridas e conhecimentos
- **Compatibilidade AcadÃªmica**: Alinhamento de formaÃ§Ã£o
- **Compatibilidade de Idiomas**: NÃ­vel de inglÃªs adequado
- **Match de Ãrea**: ExperiÃªncia na Ã¡rea de atuaÃ§Ã£o
- **Tipo de Contrato**: Alinhamento com preferÃªncias

## ğŸ”Œ API REST

### Endpoint Principal: `/api/predict`
Realiza uma prediÃ§Ã£o de compatibilidade com base nos dados da vaga e do candidato.

- **MÃ©todo**: `POST`
- **Payload**:
```json
{
  "vaga": {
    "titulo_vaga": "Desenvolvedor Python SÃªnior",
    "competencias_tecnicas_requeridas": "Python, Django, FastAPI, PostgreSQL",
    "nivel_academico": "superior",
    "nivel_ingles": "intermediÃ¡rio",
    "nivel_profissional": "sÃªnior",
    "tipo_contratacao": "clt",
    "areas_atuacao": "Tecnologia"
  },
  "candidato": {
    "conhecimentos_tecnicos": "Python, Django, PostgreSQL, Docker",
    "nivel_academico": "superior",
    "nivel_ingles": "intermediÃ¡rio",
    "area_de_atuacao": "Desenvolvimento de Software"
  }
}
```
- **Resposta**:
```json
{
  "prediction": 1,
  "percentage": "76.4%",
  "prediction_text": "ALTA QUALIDADE",
  "quality_score": 76.44,
  "analysis": { ... }
}
```

### Outros Endpoints
-   **`/api/predict_simple`**: VersÃ£o simplificada do endpoint de prediÃ§Ã£o, usada pela interface web.
-   **`/health`**: Retorna o status de saÃºde da aplicaÃ§Ã£o e do modelo de ML.
-   **`/status`**: Exibe uma pÃ¡gina HTML com o status detalhado dos componentes do sistema.

## ğŸ“ˆ MonitorizaÃ§Ã£o

A soluÃ§Ã£o inclui uma stack completa de monitoramento MLOps para acompanhar tanto a performance da aplicaÃ§Ã£o quanto a qualidade do modelo de ML.

### ServiÃ§os de Monitoramento

#### **Prometheus** (http://localhost:9090)
- Coleta de mÃ©tricas em tempo real
- MÃ©tricas de ML: prediÃ§Ãµes, distribuiÃ§Ã£o de scores, acurÃ¡cia
- MÃ©tricas de sistema: CPU, memÃ³ria, latÃªncia, throughput

#### **Grafana** (http://localhost:3000)
**Login**: `admin` / `admin123`

**Dashboards DisponÃ­veis**:
- **Main Dashboard**: MÃ©tricas de ML e aplicaÃ§Ã£o
  - Volume de prediÃ§Ãµes por minuto
  - DistribuiÃ§Ã£o de scores de qualidade
  - LatÃªncia mÃ©dia das prediÃ§Ãµes
  - Taxa de sucesso/erro
- **Infrastructure Dashboard**: MÃ©tricas de infraestrutura
  - CPU e memÃ³ria do sistema
  - Uso de disco e rede
  - Status dos containers Docker

### MÃ©tricas Principais

#### **Machine Learning**
- `hired_model_predictions_total`: Total de prediÃ§Ãµes realizadas
- `quality_score_histogram`: DistribuiÃ§Ã£o dos scores de qualidade
- `hired_model_accuracy`: AcurÃ¡cia atual do modelo
- `prediction_latency_seconds`: Tempo de resposta das prediÃ§Ãµes

#### **AplicaÃ§Ã£o**
- `flask_http_request_duration_seconds`: LatÃªncia dos endpoints
- `flask_http_request_total`: Volume de requisiÃ§Ãµes
- `flask_http_request_exceptions_total`: Taxa de erros

#### **Sistema**
- `node_cpu_seconds_total`: Uso de CPU
- `node_memory_MemAvailable_bytes`: MemÃ³ria disponÃ­vel
- `node_disk_io_time_seconds_total`: I/O de disco
- `node_network_receive_bytes_total`: TrÃ¡fego de rede

## ğŸ§ª Testes

O projeto inclui uma suÃ­te completa de testes automatizados para garantir a qualidade e confiabilidade da soluÃ§Ã£o.

### Testes Python (pytest)

```bash
# Executar todos os testes
python -m pytest tests/ -v

# Executar com coverage
python -m pytest tests/ --cov=app --cov-report=html

# Executar testes especÃ­ficos
python -m pytest tests/test_api.py::test_predict_endpoint -v
```

**Cobertura**: 80%+ de coverage em componentes crÃ­ticos

### Testes de API (Postman)

Uma coleÃ§Ã£o completa de testes estÃ¡ disponÃ­vel no diretÃ³rio `postman/`:

```bash
# Instalar Newman (CLI do Postman)
npm install -g newman

# Executar collection completa
newman run postman/otimizador-entrevistas.postman_collection.json \
  -e postman/otimizador-entrevistas.postman_environment.json

# Executar com relatÃ³rio HTML
newman run postman/otimizador-entrevistas.postman_collection.json \
  -e postman/otimizador-entrevistas.postman_environment.json \
  --reporters cli,htmlextra \
  --reporter-htmlextra-export report.html
```

#### CenÃ¡rios de Teste Postman
- **Health Check**: VerificaÃ§Ã£o de disponibilidade
- **ML Predictions**: Testes de prediÃ§Ã£o com diferentes cenÃ¡rios
- **High Quality Match**: Candidato ideal para vaga sÃªnior
- **Low Quality Match**: Candidato inadequado
- **Error Handling**: ValidaÃ§Ã£o de tratamento de erros
- **Response Structure**: ValidaÃ§Ã£o de schema de resposta
- **Performance Tests**: VerificaÃ§Ã£o de tempo de resposta

### ValidaÃ§Ãµes AutomÃ¡ticas
- âœ… Status codes (200, 400, 500)
- âœ… Tempo de resposta (< 2000ms)
- âœ… Estrutura de resposta JSON
- âœ… Tipos de dados e ranges vÃ¡lidos
- âœ… LÃ³gica de negÃ³cio e consistÃªncia

## ğŸ“ Estrutura do Projeto

```
otimizador-entrevistas-decision/
â”œâ”€â”€ app/                          # ğŸ AplicaÃ§Ã£o Flask Principal
â”‚   â”œâ”€â”€ models/                   #   ğŸ“Š Modelos ML e metadados
â”‚   â”‚   â”œâ”€â”€ pipeline_aprimorado.joblib      # Modelo Random Forest treinado
â”‚   â”‚   â””â”€â”€ model_metadata_enhanced.json   # Metadados do modelo
â”‚   â”œâ”€â”€ templates/                #   ğŸŒ Templates HTML (Jinja2)
â”‚   â”‚   â”œâ”€â”€ index.html           #     Interface principal
â”‚   â”‚   â”œâ”€â”€ status.html          #     PÃ¡gina de status
â”‚   â”‚   â””â”€â”€ vaga_detalhes.html   #     Detalhes de vaga
â”‚   â”œâ”€â”€ app.py                    #   ğŸš€ AplicaÃ§Ã£o Flask e APIs
â”‚   â”œâ”€â”€ requirements.txt          #   ğŸ“¦ DependÃªncias Python
â”‚   â””â”€â”€ Dockerfile                #   ğŸ³ Container da aplicaÃ§Ã£o
â”‚
â”œâ”€â”€ data/                         # ğŸ“„ Dados em Formato JSON
â”‚   â”œâ”€â”€ applicants.json          #   ğŸ‘¥ Dados de candidatos
â”‚   â”œâ”€â”€ prospects.json           #   ğŸ“ˆ HistÃ³rico de prospecÃ§Ãµes
â”‚   â”œâ”€â”€ vagas.json               #   ğŸ’¼ Dados de vagas
â”‚   â””â”€â”€ READ.ME.txt              #   ğŸ“– DocumentaÃ§Ã£o dos dados
â”‚
â”œâ”€â”€ notebooks/                    # ğŸ““ Jupyter Notebooks
â”‚   â””â”€â”€ Treinamento.ipynb        #   ğŸ¤– Notebook de treinamento ML
â”‚
â”œâ”€â”€ tests/                        # ğŸ§ª Testes Automatizados
â”‚   â””â”€â”€ test_api.py               #   âœ… Testes da API REST
â”‚
â”œâ”€â”€ postman/                      # ğŸ“® Testes Postman
â”‚   â”œâ”€â”€ otimizador-entrevistas.postman_collection.json  # Collection principal
â”‚   â”œâ”€â”€ otimizador-entrevistas.postman_environment.json # VariÃ¡veis ambiente
â”‚   â”œâ”€â”€ examples/                 #   ğŸ“‹ CenÃ¡rios de teste
â”‚   â”œâ”€â”€ README.md                 #   ğŸ“– DocumentaÃ§Ã£o dos testes
â”‚   â””â”€â”€ TEST_SCENARIOS.md         #   ğŸ¯ Manual de cenÃ¡rios
â”‚
â”œâ”€â”€ grafana/                      # ğŸ“Š ConfiguraÃ§Ãµes Grafana
â”‚   â”œâ”€â”€ dashboards/               #   ğŸ“ˆ Dashboards prÃ©-configurados
â”‚   â”‚   â”œâ”€â”€ main-dashboard.json           # Dashboard ML
â”‚   â”‚   â””â”€â”€ infrastructure-dashboard.json # Dashboard infraestrutura
â”‚   â””â”€â”€ provisioning/             #   âš™ï¸ ConfiguraÃ§Ãµes automÃ¡ticas
â”‚
â”œâ”€â”€ scripts/                      # ğŸ”§ Scripts de AutomaÃ§Ã£o
â”‚   â””â”€â”€ download-data.sh          #   ğŸ’¾ Download de dados
â”‚
â”œâ”€â”€ docker-compose.yml            # ğŸ³ OrquestraÃ§Ã£o de containers
â”œâ”€â”€ prometheus.yml                # ğŸ“Š ConfiguraÃ§Ã£o Prometheus
â”œâ”€â”€ nginx.conf                    # ğŸŒ ConfiguraÃ§Ã£o Nginx
â””â”€â”€ README.md                     # ğŸ“– DocumentaÃ§Ã£o principal
```

### Componentes Principais

#### **Machine Learning Pipeline**
- **Modelo**: Random Forest com 99.1% de acurÃ¡cia
- **Features**: 21 caracterÃ­sticas otimizadas
- **Target**: PadrÃµes de candidatos contratados com sucesso
- **Pipeline**: Preprocessamento + Feature Engineering + PrediÃ§Ã£o

#### **API e Interface**
- **Flask App**: API REST e interface web responsiva
- **Endpoints**: PrediÃ§Ã£o, health check, status
- **Templates**: Bootstrap 5 com JavaScript vanilla

#### **Monitoramento MLOps**
- **Prometheus**: Coleta de mÃ©tricas ML e sistema
- **Grafana**: Dashboards especializados
- **Alertas**: DegradaÃ§Ã£o de performance e falhas

## ğŸ› ï¸ Tecnologias Utilizadas

### **Machine Learning & Data Science**
- **scikit-learn 1.3.2**: Pipeline de ML, Random Forest, preprocessamento
- **pandas 2.1.4**: ManipulaÃ§Ã£o e anÃ¡lise de dados
- **numpy**: ComputaÃ§Ã£o numÃ©rica
- **joblib 1.3.2**: SerializaÃ§Ã£o de modelos ML

### **Backend & API**
- **Flask 3.0.0**: Framework web e API REST
- **Gunicorn**: Servidor WSGI para produÃ§Ã£o
- **prometheus-flask-exporter 0.23.0**: MÃ©tricas de aplicaÃ§Ã£o

### **Frontend & Interface**
- **Bootstrap 5**: Framework CSS responsivo
- **JavaScript (Vanilla)**: InteraÃ§Ãµes do frontend
- **Jinja2**: Template engine do Flask
- **HTML5/CSS3**: Estrutura e estilos

### **DevOps & ContainerizaÃ§Ã£o**
- **Docker**: ContainerizaÃ§Ã£o da aplicaÃ§Ã£o
- **Docker Compose**: OrquestraÃ§Ã£o de mÃºltiplos serviÃ§os
- **Nginx**: Proxy reverso e load balancing

### **Monitoramento & Observabilidade**
- **Prometheus**: Coleta de mÃ©tricas
- **Grafana**: Dashboards e visualizaÃ§Ãµes
- **node-exporter**: MÃ©tricas de sistema
- **cAdvisor**: MÃ©tricas de containers

### **Testes & Qualidade**
- **pytest 7.4.3**: Framework de testes Python
- **Postman/Newman**: Testes de API
- **Coverage**: AnÃ¡lise de cobertura de cÃ³digo

### **Arquitetura de Dados**
- **JSON**: Armazenamento de dados (portabilidade)
- **Git LFS**: Versionamento de arquivos grandes
- **Pandas DataFrames**: Processamento em memÃ³ria

## ğŸš€ PrÃ³ximos Passos

### Melhorias Futuras
- **Retreinamento AutomÃ¡tico**: Pipeline de CI/CD para atualizaÃ§Ã£o do modelo
- **A/B Testing**: ComparaÃ§Ã£o de diferentes versÃµes do modelo
- **Feature Store**: CentralizaÃ§Ã£o de features para reutilizaÃ§Ã£o
- **Real-time Inference**: API de prediÃ§Ã£o em tempo real via streaming

### Escalabilidade
- **Kubernetes**: Deploy em cluster para alta disponibilidade
- **Redis**: Cache de prediÃ§Ãµes frequentes
- **PostgreSQL**: MigraÃ§Ã£o para banco relacional em produÃ§Ã£o
- **Apache Kafka**: Stream processing para dados em tempo real

## ğŸ‘¨â€ğŸ’» Autor

**Mateus Bressan**  
PÃ³s-graduando em Machine Learning Engineering - FIAP  
ğŸ“§ [email@exemplo.com]  
ğŸ’¼ [LinkedIn](https://linkedin.com/in/mateus-bressan)  
ğŸ™ [GitHub](https://github.com/mbressan)  

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

---

**ğŸ“ Projeto desenvolvido como entregÃ¡vel do Datathon de Machine Learning Engineering da FIAP - Fase 5**
